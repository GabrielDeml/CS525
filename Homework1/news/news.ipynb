{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import nltk\n",
    "import string\n",
    "import scipy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "\n",
    "from multiprocessing import Pool, TimeoutError"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/gabe/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/gabe/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/gabe/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part 1"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# import the Fake.csv and True.csv files\n",
    "true = pd.read_csv('True.csv')\n",
    "fake = pd.read_csv('Fake.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Combine all of the true data into one list and tokesnize it\n",
    "true_string = ''.join(true[\"text\"])\n",
    "true_tokenized = nltk.word_tokenize(true_string)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Combine all of the fake data into one list and tokesnize it\n",
    "fake_string = ''.join(fake[\"text\"])\n",
    "fake_tokenized = nltk.word_tokenize(fake_string)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Make all the words lowercase and remove the punctuation\n",
    "true_tokenized = [word.lower() for word in true_tokenized if word.isalnum() or (not \".\" and not \",\" and not \"?\" and not \"!\")]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Make all the words lowercase and remove the punctuation\n",
    "fake_tokenized = [word.lower() for word in fake_tokenized if word.isalnum() or (not \".\" and not \",\" and not \"?\" and not \"!\")]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Print the 100 most common words in the true data\n",
    "fdist_true = FreqDist(true_tokenized)\n",
    "print(\"True: \" + str(fdist_true.most_common(100)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Print the 100 most common words in the fake data\n",
    "fdist_fake = FreqDist(fake_tokenized)\n",
    "print(\"Fake: \" + str(fdist_fake.most_common(100)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plot the 100 most common words in the true data\n",
    "fig = plt.figure(figsize = (100,20))\n",
    "fdist_true.plot(100,cumulative=False)\n",
    "fig.savefig('true_freq.png', bbox_inches = \"tight\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plot the 100 most common words in the fake data\n",
    "fig = plt.figure(figsize = (100,20))\n",
    "fdist_fake.plot(100,cumulative=False)\n",
    "fig.savefig('fake_freq.png', bbox_inches = \"tight\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Remove the stop words from the true data\n",
    "stop_words = stopwords.words('english')\n",
    "true_tokenized = [word for word in true_tokenized if word not in stop_words]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Remove the stop words from the fake data\n",
    "fake_tokenized = [word for word in fake_tokenized if word not in stop_words]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Print the 100 most common words in the true data\n",
    "fdist_true = FreqDist(true_tokenized)\n",
    "print(\"True: \" + str(fdist_true.most_common(100)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Print the 100 most common words in the fake data\n",
    "fdist_fake = FreqDist(fake_tokenized)\n",
    "print(\"Fake: \" + str(fdist_fake.most_common(100)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Lemmatize the words in the true data\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "true_tokenized = [lemmatizer.lemmatize(word) for word in true_tokenized]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Lemmatize the words in the fake data\n",
    "fake_tokenized = [lemmatizer.lemmatize(word) for word in fake_tokenized]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Print the 100 most common words in the true data\n",
    "fdist_true = FreqDist(true_tokenized)\n",
    "print(\"True: \" + str(fdist_true.most_common(100)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Print the 100 most common words in the fake data\n",
    "fdist_fake = FreqDist(fake_tokenized)\n",
    "print(\"Fake: \" + str(fdist_fake.most_common(100)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part 2"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# Set the true and fake labels\n",
    "true['label']=0\n",
    "fake['label']=1\n",
    "# Convert the true and fake data into a dataframe\n",
    "true_pandas = pd.DataFrame(true.to_numpy())\n",
    "fake_pandas = pd.DataFrame(fake.to_numpy())\n",
    "# Combine the true and fake data into one dataframe\n",
    "data = pd.concat([true_pandas,fake_pandas])\n",
    "# Print the dataframe\n",
    "print(data[4])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "        ..\n",
      "23476    1\n",
      "23477    1\n",
      "23478    1\n",
      "23479    1\n",
      "23480    1\n",
      "Name: 4, Length: 44898, dtype: object\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "# Remove unwanted elements from out data like symbols and numbers and tokenize the data\n",
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "cv = CountVectorizer(lowercase=True,stop_words='english',ngram_range = (1,1),tokenizer = token.tokenize)\n",
    "data_clean = cv.fit_transform(data[1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create a dataset from the tokenized data\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_clean, data[4].astype(\"int\"), test_size=0.2, random_state=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create a TF-IDF vectorizer\n",
    "tf=TfidfVectorizer()\n",
    "text_tf= tf.fit_transform(data[1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create a dataset from the TF-IDF vectorized data\n",
    "X_train_tf, X_test_tf, y_train_tf, y_test_tf = train_test_split(text_tf, data[4].astype(\"int\"), test_size=0.3, random_state=123)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Raw Dataset\n",
    "clf = MultinomialNB().fit(X_train, y_train)\n",
    "predicted= clf.predict(X_test)\n",
    "print(\"MultinomialNB Accuracy:\",metrics.accuracy_score(y_test, predicted))\n",
    "print(\"Precision: \" + str(metrics.precision_score(y_test, predicted, average='macro')))\n",
    "print(\"Recall: \" + str(metrics.recall_score(y_test, predicted, average='macro')))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Tfidf dataset\n",
    "clf = MultinomialNB().fit(X_train_tf, y_train_tf)\n",
    "predicted= clf.predict(X_test_tf)\n",
    "print(\"MultinomialNB Accuracy:\",metrics.accuracy_score(y_test_tf, predicted))\n",
    "print(\"Precision: \" + str(metrics.precision_score(y_test_tf, predicted, average='macro')))\n",
    "print(\"Recall: \" + str(metrics.recall_score(y_test_tf, predicted, average='macro')))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Raw dataset\n",
    "clf = LogisticRegression().fit(X_train, y_train)\n",
    "predicted= clf.predict(X_test)\n",
    "print(\"Logistic Regression Accuracy:\",metrics.accuracy_score(y_test, predicted))\n",
    "print(\"Precision: \" + str(metrics.precision_score(y_test, predicted, average='macro')))\n",
    "print(\"Recall: \" + str(metrics.recall_score(y_test, predicted, average='macro')))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Tfidf dataset\n",
    "clf = LogisticRegression().fit(X_train_tf, y_train_tf)\n",
    "predicted= clf.predict(X_test_tf)\n",
    "print(\"Logistic Regression Accuracy:\",metrics.accuracy_score(y_test_tf, predicted))\n",
    "print(\"Precision: \" + str(metrics.precision_score(y_test_tf, predicted, average='macro')))\n",
    "print(\"Recall: \" + str(metrics.recall_score(y_test_tf, predicted, average='macro')))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Classification using SVM\n",
    "# Raw datset\n",
    "clf = SVC().fit(X_train, y_train)\n",
    "predicted= clf.predict(X_test)\n",
    "print(\"SVM Accuracy:\",metrics.accuracy_score(y_test, predicted))\n",
    "print(\"Precision: \" + str(metrics.precision_score(y_test, predicted, average='macro')))\n",
    "print(\"Recall: \" + str(metrics.recall_score(y_test, predicted, average='macro')))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Tfidf dataset\n",
    "clf = SVC().fit(X_train_tf, y_train_tf)\n",
    "predicted= clf.predict(X_test_tf)\n",
    "print(\"SVM Accuracy:\",metrics.accuracy_score(y_test_tf, predicted))\n",
    "print(\"Precision: \" + str(metrics.precision_score(y_test_tf, predicted, average='macro')))\n",
    "print(\"Recall: \" + str(metrics.recall_score(y_test_tf, predicted, average='macro')))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Raw dataset\n",
    "clf = RandomForestClassifier().fit(X_train, y_train)\n",
    "predicted= clf.predict(X_test)\n",
    "print(\"Random Forest Accuracy:\",metrics.accuracy_score(y_test, predicted))\n",
    "print(\"Precision: \" + str(metrics.precision_score(y_test, predicted, average='macro')))\n",
    "print(\"Recall: \" + str(metrics.recall_score(y_test, predicted, average='macro')))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Tfidf dataset\n",
    "clf = RandomForestClassifier().fit(X_train_tf, y_train_tf)\n",
    "predicted= clf.predict(X_test_tf)\n",
    "print(\"Random Forest Accuracy:\",metrics.accuracy_score(y_test_tf, predicted))\n",
    "print(\"Precision: \" + str(metrics.precision_score(y_test_tf, predicted, average='macro')))\n",
    "print(\"Recall: \" + str(metrics.recall_score(y_test_tf, predicted, average='macro')))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part 3"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# After applying \"POS Tagging\", you can locate specific kinds of words in the collection, e.g.,nouns and verbs. \n",
    "# Please build additional classifier(s) to classify the news by leveraging POSinformation, e.g., only use the \"nouns\" or \"adj\" + \"noun\" as features. \n",
    "# Did you witness theperformance improvement (compared with the result from task 2)? why?\n",
    "\n",
    "# Pos tag then do lemmatization "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "data[1].shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(44898,)"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "def lemmatize(p : list):\n",
    "\ttoken = nltk.word_tokenize(p)\n",
    "\tpos = nltk.pos_tag(token)\n",
    "\tlem = [lemmatizer.lemmatize(word[0]) for word in pos if word[1] == \"NN\"]\n",
    "\treturn lem"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "with Pool(processes=8) as pool:\n",
    "\tnouns = pool.map(lemmatize, data[1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "with Pool(processes=8) as pool:\n",
    "\tpos_tag_tokens_false = pool.map(lemmatize, data[1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "nouns = pos_tag_tokens_true + pos_tag_tokens_fake"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# Create a list of labels for the nouns\n",
    "nouns_labels = [0] * len(pos_tag_tokens_true) + ([1] * len(pos_tag_tokens_fake))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# Create dataset split with nouns\n",
    "X_train_nouns, X_test_nouns, y_train_nouns, y_test_nouns = train_test_split(nouns, data[4].astype(\"int\"), test_size=0.3, random_state=123)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# Nouns dataset\n",
    "clf = MultinomialNB().fit(X_train_nouns, y_train_nouns)\n",
    "predicted= clf.predict(X_test_nouns)\n",
    "print(\"MultinomialNB Accuracy:\",metrics.accuracy_score(y_test_nouns, predicted))\n",
    "print(\"Precision: \" + str(metrics.precision_score(y_test_nouns, predicted, average='macro')))\n",
    "print(\"Recall: \" + str(metrics.recall_score(y_test_nouns, predicted, average='macro')))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/gabe/.local/lib/python3.9/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[list(['student', 'art', 'contest', 'painting', 'stir', 'painting', 'symbol', 'symbol', 'islam', 'hijab', 'student', 'hijab', 'congressman', 'office', 'violation', 'separation', 'church', 'state', 'activist', 'group', 'enforcement', 'immigration', 'laws.The', 'group', 'success', 'painting', 'congressman', 'student', 'art', 'competition.Because', 'complaint', 'advice', 'issue', 'protest', 'district', 'office', 'example', 'congressman', 'resident', 'activist', 'anything', 'office'])\n list(['Tune', 'broadcast', 'broadcast', 'talk', 'radio', 'custom-made', 'bar', 'fly', 'street', 'corner', 'media-maniacs', 'rascals.Join', 'contributor', 'contributor', 'episode', 'tune', 'hang', 'boil', 'analysis', 'gnashing', 'teeth', 'reject', 'club.This', 'week', 'show', 'role', 'engineering', 'protest', 'news', 'death', 'share', 'program', 'donate', 'page', 'Reference'])\n list(['favoring', 'dispute', 'neighbor', 'way', 'development', 'drilling', 'multi-billion', 'dollar', 'deepwater', 'oil', 'gas', 'project', 'row', 'development', 'oil', 'oil', 'percent', 'world', 's', 'cocoa', 'd', 'official', 'court', 'tribunal', 'correspond', 'claim', 'party', 'angle', 'line', 'news', 'judgment', 'position', 'television', 'dispute', 'work', 'drilling', 'part', 'plan', 'development', 'potential', 'executive', 'oil', 'company', 'lead', 'operator', 'project', 'statement', 'end', 'year', 'production', 'capacity', 'production', 'storage', 'vessel', 'day', 'bpd', 'project', 'ruling', 'claim', 'line', 'relief', 'oil', 'growth', 'crisis', 'compensation', 'oil', 'field', 'area', 'claim', 'loss', 'contract', 'loss', 'revenue', 'economy', 'debt', 'project', 'gold', 'producer', 'oil', 'neighbor', 'oil', 'claim', 'deal', 'border', 'sea'])\n ...\n list(['Defense', 'military', 'ambush', 'week', 'incident', 'affiliate', 'spotlight', 'counterterrorism', 'mission', 'country', 'incident', 'time', 'ambush', 'place', 'area', 'enemy', 'patrol', 'aircraft', 'delay', 'something', 'stance', 'lot', 'board', 'plane', 'patrol', 'dozen', 'attack', 'dozen', 'security', 'source', 'ambush', 'diplomat', 'knowledge', 'incident', 'intelligence', 'contingency', 'place', 'combat', 'mission', 'assistance', 'army', 'intelligence', 'surveillance', 'reconnaissance'])\n list(['conviction', 'gay', 'man', 'officer', 's', 'conviction', 'judge', 'gay', 'vice', 'squad.The', 'judge', 's', 'client', 's', 'conviction', 'conduct', 'exposure', 'nature', 'conduct', 'community', 's', 'case', 'officer', 'restroom', 'part', 'officer', 'himself.Dhanidina', 'presence', 'decoy', 'judge', 'vice', 'squad', 'conduct', 'police', 'department', 'sex', 'stings.While', 'police', 'department', 'response', 'conduct', 'judge', 'argument', 'evidence', 'police', 'gay', 'men.Jim', 'spokesman', 'police', 'sex', 'councilman', 'expert', 'witness', 'conduct', 'era', 'homosexuality', 'leftover', 'century', 'judge', 's', 'decision', 'step', 'police', 'country.Last', 'year', 'police', 'ban', 'video', 'way', 'racism', 'way', 'homophobia', 'multitude', 'police', 'target', 'entrap', 'criminalize', 'community.Photo'])\n list(['gold', 'trader', 'support', 'name', 'business', 'trader', 'court', 'filing', 'lira', 'percent', 'dollar', 'filing', 'wrongdoing', 'case', 'relationship', 'lawyer', 'request', 'comment', 'government', 'government', 'scheme', 'banker', 'custody', 'trial', 'filing', 's', 'delay', 'amount', 'work', 'difficulty', 'trial', 'preparation', 'jail', 'filing', 'government', 'evidence', 'trial', 'government', 'banking', 'scheme', 'filing', 'phone', 'call', 'defendant', 'bank', 'conduit', 'minister', 'wedding', 'day', 'wedding', 'co-defendant', 'license', 'bank', 'regulator', 'bank', 'filing', 's', 'case', 'defendant', 'trial', 'speculation', 'plea', 'case', 'et', 'al'])].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22883/24203909.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Nouns dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_nouns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_nouns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_nouns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MultinomialNB Accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_nouns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Precision: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_nouns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'macro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    661\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mitself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m         \"\"\"\n\u001b[0;32m--> 663\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    664\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36m_check_X_y\u001b[0;34m(self, X, y, reset)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m         \u001b[0;34m\"\"\"Validate X and y in fit methods.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_class_log_prior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_prior\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    570\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y cannot be None\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 956\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m    957\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0;31m# If input is 1D raise error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    762\u001b[0m                     \u001b[0;34m\"Expected 2D array, got 1D array instead:\\narray={}.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[list(['student', 'art', 'contest', 'painting', 'stir', 'painting', 'symbol', 'symbol', 'islam', 'hijab', 'student', 'hijab', 'congressman', 'office', 'violation', 'separation', 'church', 'state', 'activist', 'group', 'enforcement', 'immigration', 'laws.The', 'group', 'success', 'painting', 'congressman', 'student', 'art', 'competition.Because', 'complaint', 'advice', 'issue', 'protest', 'district', 'office', 'example', 'congressman', 'resident', 'activist', 'anything', 'office'])\n list(['Tune', 'broadcast', 'broadcast', 'talk', 'radio', 'custom-made', 'bar', 'fly', 'street', 'corner', 'media-maniacs', 'rascals.Join', 'contributor', 'contributor', 'episode', 'tune', 'hang', 'boil', 'analysis', 'gnashing', 'teeth', 'reject', 'club.This', 'week', 'show', 'role', 'engineering', 'protest', 'news', 'death', 'share', 'program', 'donate', 'page', 'Reference'])\n list(['favoring', 'dispute', 'neighbor', 'way', 'development', 'drilling', 'multi-billion', 'dollar', 'deepwater', 'oil', 'gas', 'project', 'row', 'development', 'oil', 'oil', 'percent', 'world', 's', 'cocoa', 'd', 'official', 'court', 'tribunal', 'correspond', 'claim', 'party', 'angle', 'line', 'news', 'judgment', 'position', 'television', 'dispute', 'work', 'drilling', 'part', 'plan', 'development', 'potential', 'executive', 'oil', 'company', 'lead', 'operator', 'project', 'statement', 'end', 'year', 'production', 'capacity', 'production', 'storage', 'vessel', 'day', 'bpd', 'project', 'ruling', 'claim', 'line', 'relief', 'oil', 'growth', 'crisis', 'compensation', 'oil', 'field', 'area', 'claim', 'loss', 'contract', 'loss', 'revenue', 'economy', 'debt', 'project', 'gold', 'producer', 'oil', 'neighbor', 'oil', 'claim', 'deal', 'border', 'sea'])\n ...\n list(['Defense', 'military', 'ambush', 'week', 'incident', 'affiliate', 'spotlight', 'counterterrorism', 'mission', 'country', 'incident', 'time', 'ambush', 'place', 'area', 'enemy', 'patrol', 'aircraft', 'delay', 'something', 'stance', 'lot', 'board', 'plane', 'patrol', 'dozen', 'attack', 'dozen', 'security', 'source', 'ambush', 'diplomat', 'knowledge', 'incident', 'intelligence', 'contingency', 'place', 'combat', 'mission', 'assistance', 'army', 'intelligence', 'surveillance', 'reconnaissance'])\n list(['conviction', 'gay', 'man', 'officer', 's', 'conviction', 'judge', 'gay', 'vice', 'squad.The', 'judge', 's', 'client', 's', 'conviction', 'conduct', 'exposure', 'nature', 'conduct', 'community', 's', 'case', 'officer', 'restroom', 'part', 'officer', 'himself.Dhanidina', 'presence', 'decoy', 'judge', 'vice', 'squad', 'conduct', 'police', 'department', 'sex', 'stings.While', 'police', 'department', 'response', 'conduct', 'judge', 'argument', 'evidence', 'police', 'gay', 'men.Jim', 'spokesman', 'police', 'sex', 'councilman', 'expert', 'witness', 'conduct', 'era', 'homosexuality', 'leftover', 'century', 'judge', 's', 'decision', 'step', 'police', 'country.Last', 'year', 'police', 'ban', 'video', 'way', 'racism', 'way', 'homophobia', 'multitude', 'police', 'target', 'entrap', 'criminalize', 'community.Photo'])\n list(['gold', 'trader', 'support', 'name', 'business', 'trader', 'court', 'filing', 'lira', 'percent', 'dollar', 'filing', 'wrongdoing', 'case', 'relationship', 'lawyer', 'request', 'comment', 'government', 'government', 'scheme', 'banker', 'custody', 'trial', 'filing', 's', 'delay', 'amount', 'work', 'difficulty', 'trial', 'preparation', 'jail', 'filing', 'government', 'evidence', 'trial', 'government', 'banking', 'scheme', 'filing', 'phone', 'call', 'defendant', 'bank', 'conduit', 'minister', 'wedding', 'day', 'wedding', 'co-defendant', 'license', 'bank', 'regulator', 'bank', 'filing', 's', 'case', 'defendant', 'trial', 'speculation', 'plea', 'case', 'et', 'al'])].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# POS Tagging dataset\n",
    "clf = LogisticRegression().fit(X_train_pos, y_train_pos)\n",
    "predicted= clf.predict(X_test_pos)\n",
    "print(\"Logistic Regression Accuracy:\",metrics.accuracy_score(y_test_pos, predicted))\n",
    "print(\"Precision: \" + str(metrics.precision_score(y_test_pos, predicted, average='macro')))\n",
    "print(\"Recall: \" + str(metrics.recall_score(y_test_pos, predicted, average='macro')))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# POS Tagging dataset\n",
    "clf = SVC().fit(X_train_pos, y_train_pos)\n",
    "predicted= clf.predict(X_test_pos)\n",
    "print(\"SVM Accuracy:\",metrics.accuracy_score(y_test_pos, predicted))\n",
    "print(\"Precision: \" + str(metrics.precision_score(y_test_pos, predicted, average='macro')))\n",
    "print(\"Recall: \" + str(metrics.recall_score(y_test_pos, predicted, average='macro')))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# POS Tagging dataset\n",
    "clf = RandomForestClassifier().fit(X_train_pos, y_train_pos)\n",
    "predicted= clf.predict(X_test_pos)\n",
    "print(\"Random Forest Accuracy:\",metrics.accuracy_score(y_test_pos, predicted))\n",
    "print(\"Precision: \" + str(metrics.precision_score(y_test_pos, predicted, average='macro')))\n",
    "print(\"Recall: \" + str(metrics.recall_score(y_test_pos, predicted, average='macro')))"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit"
  },
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}