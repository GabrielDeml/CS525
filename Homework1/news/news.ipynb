{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import nltk\n",
    "import string\n",
    "import scipy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part 1"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# import the Fake.csv and True.csv files\n",
    "fake = pd.read_csv('Fake.csv')\n",
    "true = pd.read_csv('True.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Combine all of the true data into one list and tokesnize it\n",
    "true_string = ''.join(true[\"text\"])\n",
    "true_tokenized = nltk.word_tokenize(true_string)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Combine all of the fake data into one list and tokesnize it\n",
    "fake_string = ''.join(fake[\"text\"])\n",
    "fake_tokenized = nltk.word_tokenize(fake_string)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Make all the words lowercase and remove the punctuation\n",
    "true_tokenized = [word.lower() for word in true_tokenized if word.isalnum() or (not \".\" and not \",\" and not \"?\" and not \"!\")]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Make all the words lowercase and remove the punctuation\n",
    "fake_tokenized = [word.lower() for word in fake_tokenized if word.isalnum() or (not \".\" and not \",\" and not \"?\" and not \"!\")]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Print the 100 most common words in the true data\n",
    "fdist_true = FreqDist(true_tokenized)\n",
    "print(\"True: \" + str(fdist_true.most_common(100)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Print the 100 most common words in the fake data\n",
    "fdist_fake = FreqDist(fake_tokenized)\n",
    "print(\"Fake: \" + str(fdist_fake.most_common(100)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plot the 100 most common words in the true data\n",
    "fig = plt.figure(figsize = (100,20))\n",
    "fdist_true.plot(100,cumulative=False)\n",
    "fig.savefig('true_freq.png', bbox_inches = \"tight\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plot the 100 most common words in the fake data\n",
    "fig = plt.figure(figsize = (100,20))\n",
    "fdist_fake.plot(100,cumulative=False)\n",
    "fig.savefig('fake_freq.png', bbox_inches = \"tight\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Remove the stop words from the true data\n",
    "stop_words = stopwords.words('english')\n",
    "true_tokenized = [word for word in true_tokenized if word not in stop_words]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Remove the stop words from the fake data\n",
    "fake_tokenized = [word for word in fake_tokenized if word not in stop_words]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Print the 100 most common words in the true data\n",
    "fdist_true = FreqDist(true_tokenized)\n",
    "print(\"True: \" + str(fdist_true.most_common(100)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Print the 100 most common words in the fake data\n",
    "fdist_fake = FreqDist(fake_tokenized)\n",
    "print(\"Fake: \" + str(fdist_fake.most_common(100)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Lemmatize the words in the true data\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "true_tokenized = [lemmatizer.lemmatize(word) for word in true_tokenized]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Lemmatize the words in the fake data\n",
    "fake_tokenized = [lemmatizer.lemmatize(word) for word in fake_tokenized]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Print the 100 most common words in the true data\n",
    "fdist_true = FreqDist(true_tokenized)\n",
    "print(\"True: \" + str(fdist_true.most_common(100)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Print the 100 most common words in the fake data\n",
    "fdist_fake = FreqDist(fake_tokenized)\n",
    "print(\"Fake: \" + str(fdist_fake.most_common(100)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part 2"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Set the true and fake labels\n",
    "true['label']=0\n",
    "fake['label']=1\n",
    "# Convert the true and fake data into a dataframe\n",
    "true_pandas = pd.DataFrame(true.to_numpy())\n",
    "fake_pandas = pd.DataFrame(fake.to_numpy())\n",
    "# Combine the true and fake data into one dataframe\n",
    "data = pd.concat([true_pandas,fake_pandas])\n",
    "# Print the dataframe\n",
    "print(data[4])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "# Remove unwanted elements from out data like symbols and numbers and tokenize the data\n",
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "cv = CountVectorizer(lowercase=True,stop_words='english',ngram_range = (1,1),tokenizer = token.tokenize)\n",
    "data_clean = cv.fit_transform(data[1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create a dataset from the tokenized data\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_clean, data[4].astype(\"int\"), test_size=0.2, random_state=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create a TF-IDF vectorizer\n",
    "tf=TfidfVectorizer()\n",
    "text_tf= tf.fit_transform(data[1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create a dataset from the TF-IDF vectorized data\n",
    "X_train_tf, X_test_tf, y_train_tf, y_test_tf = train_test_split(text_tf, data[4].astype(\"int\"), test_size=0.3, random_state=123)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Raw Dataset\n",
    "clf = MultinomialNB().fit(X_train, y_train)\n",
    "predicted= clf.predict(X_test)\n",
    "print(\"MultinomialNB Accuracy:\",metrics.accuracy_score(y_test, predicted))\n",
    "print(\"Precision: \" + str(metrics.precision_score(y_test, predicted, average='macro')))\n",
    "print(\"Recall: \" + str(metrics.recall_score(y_test, predicted, average='macro')))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Tfidf dataset\n",
    "clf = MultinomialNB().fit(X_train_tf, y_train_tf)\n",
    "predicted= clf.predict(X_test_tf)\n",
    "print(\"MultinomialNB Accuracy:\",metrics.accuracy_score(y_test_tf, predicted))\n",
    "print(\"Precision: \" + str(metrics.precision_score(y_test_tf, predicted, average='macro')))\n",
    "print(\"Recall: \" + str(metrics.recall_score(y_test_tf, predicted, average='macro')))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Raw dataset\n",
    "clf = LogisticRegression().fit(X_train, y_train)\n",
    "predicted= clf.predict(X_test)\n",
    "print(\"Logistic Regression Accuracy:\",metrics.accuracy_score(y_test, predicted))\n",
    "print(\"Precision: \" + str(metrics.precision_score(y_test, predicted, average='macro')))\n",
    "print(\"Recall: \" + str(metrics.recall_score(y_test, predicted, average='macro')))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Tfidf dataset\n",
    "clf = LogisticRegression().fit(X_train_tf, y_train_tf)\n",
    "predicted= clf.predict(X_test_tf)\n",
    "print(\"Logistic Regression Accuracy:\",metrics.accuracy_score(y_test_tf, predicted))\n",
    "print(\"Precision: \" + str(metrics.precision_score(y_test_tf, predicted, average='macro')))\n",
    "print(\"Recall: \" + str(metrics.recall_score(y_test_tf, predicted, average='macro')))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Classification using SVM\n",
    "# Raw datset\n",
    "clf = SVC().fit(X_train, y_train)\n",
    "predicted= clf.predict(X_test)\n",
    "print(\"SVM Accuracy:\",metrics.accuracy_score(y_test, predicted))\n",
    "print(\"Precision: \" + str(metrics.precision_score(y_test, predicted, average='macro')))\n",
    "print(\"Recall: \" + str(metrics.recall_score(y_test, predicted, average='macro')))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Tfidf dataset\n",
    "clf = SVC().fit(X_train_tf, y_train_tf)\n",
    "predicted= clf.predict(X_test_tf)\n",
    "print(\"SVM Accuracy:\",metrics.accuracy_score(y_test_tf, predicted))\n",
    "print(\"Precision: \" + str(metrics.precision_score(y_test_tf, predicted, average='macro')))\n",
    "print(\"Recall: \" + str(metrics.recall_score(y_test_tf, predicted, average='macro')))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Raw dataset\n",
    "clf = RandomForestClassifier().fit(X_train, y_train)\n",
    "predicted= clf.predict(X_test)\n",
    "print(\"Random Forest Accuracy:\",metrics.accuracy_score(y_test, predicted))\n",
    "print(\"Precision: \" + str(metrics.precision_score(y_test, predicted, average='macro')))\n",
    "print(\"Recall: \" + str(metrics.recall_score(y_test, predicted, average='macro')))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Tfidf dataset\n",
    "clf = RandomForestClassifier().fit(X_train_tf, y_train_tf)\n",
    "predicted= clf.predict(X_test_tf)\n",
    "print(\"Random Forest Accuracy:\",metrics.accuracy_score(y_test_tf, predicted))\n",
    "print(\"Precision: \" + str(metrics.precision_score(y_test_tf, predicted, average='macro')))\n",
    "print(\"Recall: \" + str(metrics.recall_score(y_test_tf, predicted, average='macro')))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part 3"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# After applying \"POS Tagging\", you can locate specific kinds of words in the collection, e.g.,nouns and verbs. \n",
    "# Please build additional classifier(s) to classify the news by leveraging POSinformation, e.g., only use the \"nouns\" or \"adj\" + \"noun\" as features. \n",
    "# Did you witness theperformance improvement (compared with the result from task 2)? why?\n",
    "\n",
    "# Pos tag then do lemmatization "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Pos tag \n",
    "for sentence in pos_tag_true:\n",
    "\tfor word in sentence:\n",
    "\t\tpos_tag_true = nltk.pos_tag(word)\n",
    "\t\tpos_tag_fake = nltk.pos_tag()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# Create a list of lemmatized pos tagged words for true data\n",
    "pos_tag_tokens_true = []\n",
    "for p in true['text']:\n",
    "\ttoken = nltk.word_tokenize(p)\n",
    "\tpos = nltk.pos_tag(token)\n",
    "\tlem = [(lemmatizer.lemmatize(word[0]), word[1]) for word in pos if word[1] == \"NN\"]\n",
    "\tpos_tag_tokens_true.append(lem)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create a list of lemmatized pos tagged words for fake data\n",
    "pos_tag_tokens_fake = []\n",
    "for p in fake['text']:\n",
    "\ttoken = nltk.word_tokenize(p)\n",
    "\tpos = nltk.pos_tag(token)\n",
    "\tlem = [(lemmatizer.lemmatize(word[0]), word[1]) for word in pos if word[1] == \"NN\"]\n",
    "\tpos_tag_tokens_fake.append(lem)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Lemmatizatze the pos_tag\n",
    "# Lemmatize the words in the true data \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "for i in pos_tag_tokens_true: \n",
    "\ttrue_pos_tokenized = [(lemmatizer.lemmatize(word[0]), word[1]) for word in sentence for sentence in pos_tag_true]\n",
    "# fake_pos_tokenized = [(lemmatizer.lemmatize(word[0]), word[1]) for word in pos_tag_fake]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(true_pos_tokenized[:10])\n",
    "print(len(fake_pos_tokenized))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# POS tag the data\n",
    "full_tokenized = true_tokenized + fake_tokenized\n",
    "pos_tag = nltk.pos_tag(full_tokenized)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create a list of just nouns from pos_tag_tokens_true\n",
    "nouns_true = []\n",
    "for p in pos_tag_tokens_true:\n",
    "\tnouns = [word for word,pos in p if pos == 'NN']\n",
    "\tnouns_true.append(nouns)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create a list of just nouns from pos_tag_tokens_fake\n",
    "nouns_fake = []\n",
    "for p in pos_tag_tokens_fake:\n",
    "\tnouns = [word for word,pos in p if pos == 'NN']\n",
    "\tnouns_fake.append(nouns)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "nouns = nouns_true + nouns_fake"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(nouns[-10:])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create a list of labels for the nouns\n",
    "nouns_labels = [0] * len(nouns_true) + ([1] * len(nouns_fake))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create dataset split with nouns\n",
    "X_train_nouns, X_test_nouns, y_train_nouns, y_test_nouns = train_test_split(nouns, nouns_labels, test_size=0.3, random_state=123)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(nouns_labels[:10])\n",
    "print(nouns_labels[-10:])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train_pos, X_test_pos, y_train_pos, y_test_pos = train_test_split(pos_tag, nouns_labels, test_size=0.3, random_state=123)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Nouns dataset\n",
    "clf = MultinomialNB().fit(X_train_nouns, y_train_nouns)\n",
    "predicted= clf.predict(X_test_nouns)\n",
    "print(\"MultinomialNB Accuracy:\",metrics.accuracy_score(y_test_nouns, predicted))\n",
    "print(\"Precision: \" + str(metrics.precision_score(y_test_nouns, predicted, average='macro')))\n",
    "print(\"Recall: \" + str(metrics.recall_score(y_test_nouns, predicted, average='macro')))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# POS Tagging dataset\n",
    "clf = LogisticRegression().fit(X_train_pos, y_train_pos)\n",
    "predicted= clf.predict(X_test_pos)\n",
    "print(\"Logistic Regression Accuracy:\",metrics.accuracy_score(y_test_pos, predicted))\n",
    "print(\"Precision: \" + str(metrics.precision_score(y_test_pos, predicted, average='macro')))\n",
    "print(\"Recall: \" + str(metrics.recall_score(y_test_pos, predicted, average='macro')))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# POS Tagging dataset\n",
    "clf = SVC().fit(X_train_pos, y_train_pos)\n",
    "predicted= clf.predict(X_test_pos)\n",
    "print(\"SVM Accuracy:\",metrics.accuracy_score(y_test_pos, predicted))\n",
    "print(\"Precision: \" + str(metrics.precision_score(y_test_pos, predicted, average='macro')))\n",
    "print(\"Recall: \" + str(metrics.recall_score(y_test_pos, predicted, average='macro')))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# POS Tagging dataset\n",
    "clf = RandomForestClassifier().fit(X_train_pos, y_train_pos)\n",
    "predicted= clf.predict(X_test_pos)\n",
    "print(\"Random Forest Accuracy:\",metrics.accuracy_score(y_test_pos, predicted))\n",
    "print(\"Precision: \" + str(metrics.precision_score(y_test_pos, predicted, average='macro')))\n",
    "print(\"Recall: \" + str(metrics.recall_score(y_test_pos, predicted, average='macro')))"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit"
  },
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}