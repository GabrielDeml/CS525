{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv('Reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the data\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "reviews_without_stopwords = [word for word in reviews['Text'].str.split() if word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set everything to lower case and remove punctuation\n",
    "reviews_without_stopwords_or_punctuation = []\n",
    "for st in reviews_without_stopwords:\n",
    "\tfor word in st:\n",
    "\t\tif word not in string.punctuation:\n",
    "\t\t\treviews_without_stopwords_or_punctuation.append(word.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: [('the', 1831301), ('i', 1428461), ('and', 1259937), ('a', 1191447), ('to', 1003664), ('of', 797023), ('it', 772956), ('is', 720635), ('this', 632581), ('for', 538682), ('in', 531348), ('my', 452684), ('that', 412869), ('but', 357050), ('with', 344967), ('have', 340556), ('not', 318174), ('are', 313689), ('was', 311484), ('you', 308452), ('they', 280462), ('as', 271513), ('on', 260662), ('/><br', 257584), ('like', 240930), ('so', 233352), ('these', 208138), ('be', 183368), ('at', 176461), ('or', 172278), ('just', 167810), ('very', 163162), ('if', 158549), ('one', 151460), ('them', 150602), ('good', 147853), ('from', 142401), (\"it's\", 133093), ('when', 132589), ('all', 131070), ('great', 130957), ('has', 129917), ('can', 128073), ('taste', 127457), ('we', 126031), ('will', 125047), ('would', 121748), ('love', 121572), ('had', 119483), ('more', 118712), ('coffee', 115167), ('than', 113913), ('get', 105629), ('other', 104496), ('product', 101020), ('some', 99539), ('no', 99207), ('about', 98987), ('really', 97440), ('only', 97262), ('out', 96485), ('tea', 95106), ('flavor', 93135), ('me', 92160), ('an', 89685), (\"don't\", 88566), ('your', 87530), ('food', 86883), ('up', 83587), ('because', 83241), ('little', 81564), ('much', 81453), ('were', 79472), ('it.', 78707), ('been', 76805), ('use', 76303), ('what', 74977), ('also', 72694), ('am', 72470), ('even', 71580), ('buy', 71498), ('do', 70714), ('which', 70476), ('by', 70439), ('she', 69760), ('find', 69122), ('he', 68770), (\"i'm\", 68756), ('tried', 68712), ('make', 68540), (\"i've\", 68124), ('after', 67214), ('there', 66396), ('too', 66309), ('any', 65498), ('best', 63498), ('their', 61174), ('eat', 59276), ('dog', 58456), ('our', 57422)]\n"
     ]
    }
   ],
   "source": [
    "from nltk.probability import FreqDist\n",
    "fdist_true = FreqDist(reviews_without_stopwords_or_punctuation)\n",
    "print(\"True: \" + str(fdist_true.most_common(100)))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
